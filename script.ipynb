{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv')\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75788</th>\n",
       "      <td>151772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75789</th>\n",
       "      <td>151773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75790</th>\n",
       "      <td>151776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75791</th>\n",
       "      <td>151777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75792</th>\n",
       "      <td>151780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75793</th>\n",
       "      <td>151781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75794</th>\n",
       "      <td>151782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75795</th>\n",
       "      <td>151784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75796</th>\n",
       "      <td>151785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75797</th>\n",
       "      <td>151786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75798</th>\n",
       "      <td>151788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75799</th>\n",
       "      <td>151789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75800</th>\n",
       "      <td>151790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75801</th>\n",
       "      <td>151791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75802</th>\n",
       "      <td>151803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75803</th>\n",
       "      <td>151812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75804</th>\n",
       "      <td>151814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75805</th>\n",
       "      <td>151817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75806</th>\n",
       "      <td>151819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75807</th>\n",
       "      <td>151822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75808</th>\n",
       "      <td>151823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75809</th>\n",
       "      <td>151824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75810</th>\n",
       "      <td>151826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75811</th>\n",
       "      <td>151827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75812</th>\n",
       "      <td>151828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75813</th>\n",
       "      <td>151831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75814</th>\n",
       "      <td>151832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75815</th>\n",
       "      <td>151833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75816</th>\n",
       "      <td>151834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75817</th>\n",
       "      <td>151837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75818 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  TARGET\n",
       "0           2       0\n",
       "1           5       0\n",
       "2           6       0\n",
       "3           7       0\n",
       "4           9       0\n",
       "5          11       0\n",
       "6          12       0\n",
       "7          15       0\n",
       "8          16       0\n",
       "9          17       0\n",
       "10         19       0\n",
       "11         21       0\n",
       "12         22       0\n",
       "13         24       0\n",
       "14         27       0\n",
       "15         28       0\n",
       "16         30       0\n",
       "17         33       0\n",
       "18         35       0\n",
       "19         37       0\n",
       "20         38       0\n",
       "21         40       0\n",
       "22         41       0\n",
       "23         44       0\n",
       "24         46       0\n",
       "25         47       0\n",
       "26         48       0\n",
       "27         50       0\n",
       "28         52       0\n",
       "29         53       0\n",
       "...       ...     ...\n",
       "75788  151772       0\n",
       "75789  151773       0\n",
       "75790  151776       0\n",
       "75791  151777       0\n",
       "75792  151780       0\n",
       "75793  151781       0\n",
       "75794  151782       0\n",
       "75795  151784       0\n",
       "75796  151785       0\n",
       "75797  151786       0\n",
       "75798  151788       0\n",
       "75799  151789       0\n",
       "75800  151790       0\n",
       "75801  151791       0\n",
       "75802  151803       0\n",
       "75803  151812       0\n",
       "75804  151814       0\n",
       "75805  151817       0\n",
       "75806  151819       0\n",
       "75807  151822       0\n",
       "75808  151823       0\n",
       "75809  151824       0\n",
       "75810  151826       0\n",
       "75811  151827       0\n",
       "75812  151828       0\n",
       "75813  151831       0\n",
       "75814  151832       0\n",
       "75815  151833       0\n",
       "75816  151834       0\n",
       "75817  151837       0\n",
       "\n",
       "[75818 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = train_data.columns[1:-1]\n",
    "pca = PCA(n_components=2)\n",
    "x_train_projected = pca.fit_transform(normalize(train_data[features], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00761944, -0.00442549],\n",
       "       [ 0.00490196,  0.02780408],\n",
       "       [ 0.00683416, -0.00382882],\n",
       "       ..., \n",
       "       [ 0.00684313, -0.00384208],\n",
       "       [ 0.00680632, -0.00380473],\n",
       "       [ 0.00757921, -0.00433865]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!\n",
      "Change num_rounds to 350\n",
      "('Fold:', 0)\n",
      "('Blind Log Loss:', 0.49393033418046411)\n",
      "('Blind ROC:', 0.8175398630148204)\n",
      "('Fold:', 1)\n",
      "('Blind Log Loss:', 0.49435497596360156)\n",
      "('Blind ROC:', 0.80599430729850552)\n",
      "('Fold:', 2)\n",
      "('Blind Log Loss:', 0.49403415419998309)\n",
      "('Blind ROC:', 0.79642437366928753)\n",
      "('Fold:', 3)\n",
      "('Blind Log Loss:', 0.4939637132669179)\n",
      "('Blind ROC:', 0.82313713908939801)\n",
      "('Fold:', 4)\n",
      "('Blind Log Loss:', 0.49402956226661748)\n",
      "('Blind ROC:', 0.83416234339172579)\n",
      "('Fold:', 5)\n",
      "('Blind Log Loss:', 0.49399184318192224)\n",
      "('Blind ROC:', 0.80979554523318853)\n",
      "('Fold:', 6)\n",
      "('Blind Log Loss:', 0.49369357178961404)\n",
      "('Blind ROC:', 0.83148010034578612)\n",
      "('Fold:', 7)\n",
      "('Blind Log Loss:', 0.49339523600202206)\n",
      "('Blind ROC:', 0.85343108234843368)\n",
      "('Fold:', 8)\n",
      "('Blind Log Loss:', 0.49361290130751995)\n",
      "('Blind ROC:', 0.82746290462493721)\n",
      "('Fold:', 9)\n",
      "('Blind Log Loss:', 0.49425721791147825)\n",
      "('Blind ROC:', 0.81247409030726392)\n",
      "('Average Log Loss:', 0.4935990347823197)\n",
      "('Average ROC:', 0.84063354566605764)\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "print('Started!')\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test =  pd.read_csv('./data/test.csv')\n",
    "features = train.columns[1:-1]\n",
    "train.insert(1, 'SumZeros', (train[features] == 0).astype(int).sum(axis=1))\n",
    "test.insert(1, 'SumZeros', (test[features] == 0).astype(int).sum(axis=1))\n",
    "\n",
    "remove = []\n",
    "c = train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = train[c[i]].values\n",
    "    for j in range(i+1, len(c)):\n",
    "        if np.array_equal(v, train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "train.drop(remove, axis=1, inplace=True)\n",
    "test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "remove = []\n",
    "for col in train.columns:\n",
    "    if train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "train.drop(remove, axis=1, inplace=True)\n",
    "test.drop(remove, axis=1, inplace=True)\n",
    "features = train.columns[1:-1]\n",
    "pca = PCA(n_components=2)\n",
    "x_train_projected = pca.fit_transform(normalize(train[features], axis=0))\n",
    "x_test_projected = pca.transform(normalize(test[features], axis=0))\n",
    "train.insert(1, 'PCAOne', x_train_projected[:, 0])\n",
    "train.insert(1, 'PCATwo', x_train_projected[:, 1])\n",
    "test.insert(1, 'PCAOne', x_test_projected[:, 0])\n",
    "test.insert(1, 'PCATwo', x_test_projected[:, 1])\n",
    "tokeep = ['num_var39_0',  # 0.00031104199066874026\n",
    "          'ind_var13',  # 0.00031104199066874026\n",
    "          'num_op_var41_comer_ult3',  # 0.00031104199066874026\n",
    "          'num_var43_recib_ult1',  # 0.00031104199066874026\n",
    "          'imp_op_var41_comer_ult3',  # 0.00031104199066874026\n",
    "          'num_var8',  # 0.00031104199066874026\n",
    "          'num_var42',  # 0.00031104199066874026\n",
    "          'num_var30',  # 0.00031104199066874026\n",
    "          'saldo_var8',  # 0.00031104199066874026\n",
    "          'num_op_var39_efect_ult3',  # 0.00031104199066874026\n",
    "          'num_op_var39_comer_ult3',  # 0.00031104199066874026\n",
    "          'num_var41_0',  # 0.0006220839813374805\n",
    "          'num_op_var39_ult3',  # 0.0006220839813374805\n",
    "          'saldo_var13',  # 0.0009331259720062209\n",
    "          'num_var30_0',  # 0.0009331259720062209\n",
    "          'ind_var37_cte',  # 0.0009331259720062209\n",
    "          'ind_var39_0',  # 0.001244167962674961\n",
    "          'num_var5',  # 0.0015552099533437014\n",
    "          'ind_var10_ult1',  # 0.0015552099533437014\n",
    "          'num_op_var39_hace2',  # 0.0018662519440124418\n",
    "          'num_var22_hace2',  # 0.0018662519440124418\n",
    "          'num_var35',  # 0.0018662519440124418\n",
    "          'ind_var30',  # 0.0018662519440124418\n",
    "          'num_med_var22_ult3',  # 0.002177293934681182\n",
    "          'imp_op_var41_efect_ult1',  # 0.002488335925349922\n",
    "          'var36',  # 0.0027993779160186624\n",
    "          'num_med_var45_ult3',  # 0.003110419906687403\n",
    "          'imp_op_var39_ult1',  # 0.0037325038880248835\n",
    "          'imp_op_var39_comer_ult3',  # 0.0037325038880248835\n",
    "          'imp_trans_var37_ult1',  # 0.004043545878693624\n",
    "          'num_var5_0',  # 0.004043545878693624\n",
    "          'num_var45_ult1',  # 0.004665629860031105\n",
    "          'ind_var41_0',  # 0.0052877138413685845\n",
    "          'imp_op_var41_ult1',  # 0.0052877138413685845\n",
    "          'num_var8_0',  # 0.005598755832037325\n",
    "          'imp_op_var41_efect_ult3',  # 0.007153965785381027\n",
    "          'num_op_var41_ult3',  # 0.007153965785381027\n",
    "          'num_var22_hace3',  # 0.008087091757387248\n",
    "          'num_var4',  # 0.008087091757387248\n",
    "          'imp_op_var39_comer_ult1',  # 0.008398133748055987\n",
    "          'num_var45_ult3',  # 0.008709175738724729\n",
    "          'ind_var5',  # 0.009953343701399688\n",
    "          'imp_op_var39_efect_ult3',  # 0.009953343701399688\n",
    "          'num_meses_var5_ult3',  # 0.009953343701399688\n",
    "          'saldo_var42',  # 0.01181959564541213\n",
    "          'imp_op_var39_efect_ult1',  # 0.013374805598755831\n",
    "          'PCATwo',  # 0.013996889580093312\n",
    "          'num_var45_hace2',  # 0.014618973561430793\n",
    "          'num_var22_ult1',  # 0.017107309486780714\n",
    "          'saldo_medio_var5_ult1',  # 0.017418351477449457\n",
    "          'PCAOne',  # 0.018040435458786936\n",
    "          'saldo_var5',  # 0.0208398133748056\n",
    "          'ind_var8_0',  # 0.021150855365474338\n",
    "          'ind_var5_0',  # 0.02177293934681182\n",
    "          'num_meses_var39_vig_ult3',  # 0.024572317262830483\n",
    "          'saldo_medio_var5_ult3',  # 0.024883359253499222\n",
    "          'num_var45_hace3',  # 0.026749611197511663\n",
    "          'num_var22_ult3',  # 0.03452566096423017\n",
    "          'saldo_medio_var5_hace3',  # 0.04074650077760498\n",
    "          'saldo_medio_var5_hace2',  # 0.04292379471228616\n",
    "          'SumZeros',  # 0.04696734059097978\n",
    "          'saldo_var30',  # 0.09611197511664074\n",
    "          'var38',  # 0.1390357698289269\n",
    "          'var15']  # 0.20964230171073095\n",
    "features = train.columns[1:-1]\n",
    "todrop = list(set(tokeep).difference(set(features)))\n",
    "train.drop(todrop, inplace=True, axis=1)\n",
    "test.drop(todrop, inplace=True, axis=1)\n",
    "features = train.columns[1:-1]\n",
    "split = 10\n",
    "skf = StratifiedKFold(train.TARGET.values,\n",
    "                      n_folds=split,\n",
    "                      shuffle=False,\n",
    "                      random_state=42)\n",
    "\n",
    "train_preds = None\n",
    "test_preds = None\n",
    "visibletrain = blindtrain = train\n",
    "index = 0\n",
    "print('Change num_rounds to 350')\n",
    "num_rounds = 10\n",
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"eta\"] = 0.03\n",
    "params[\"subsample\"] = 0.8\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 5\n",
    "params[\"min_child_weight\"] = 1\n",
    "params[\"eval_metric\"] = \"auc\"\n",
    "for train_index, test_index in skf:\n",
    "    print('Fold:', index)\n",
    "    visibletrain = train.iloc[train_index]\n",
    "    blindtrain = train.iloc[test_index]\n",
    "    dvisibletrain = \\\n",
    "        xgb.DMatrix(csr_matrix(visibletrain[features]),\n",
    "                    visibletrain.TARGET.values,\n",
    "                    silent=True)\n",
    "    dblindtrain = \\\n",
    "        xgb.DMatrix(csr_matrix(blindtrain[features]),\n",
    "                    blindtrain.TARGET.values,\n",
    "                    silent=True)\n",
    "    watchlist = [(dblindtrain, 'eval'), (dvisibletrain, 'train')]\n",
    "    clf = xgb.train(params, dvisibletrain, num_rounds,\n",
    "                    evals=watchlist, early_stopping_rounds=50,\n",
    "                    verbose_eval=False)\n",
    "\n",
    "    blind_preds = clf.predict(dblindtrain)\n",
    "    print('Blind Log Loss:', log_loss(blindtrain.TARGET.values,\n",
    "                                      blind_preds))\n",
    "    print('Blind ROC:', roc_auc_score(blindtrain.TARGET.values,\n",
    "                                      blind_preds))\n",
    "    index = index+1\n",
    "    del visibletrain\n",
    "    del blindtrain\n",
    "    del dvisibletrain\n",
    "    del dblindtrain\n",
    "    gc.collect()\n",
    "    dfulltrain = \\\n",
    "        xgb.DMatrix(csr_matrix(train[features]),\n",
    "                    train.TARGET.values,\n",
    "                    silent=True)\n",
    "    dfulltest = \\\n",
    "        xgb.DMatrix(csr_matrix(test[features]),\n",
    "                    silent=True)\n",
    "    if(train_preds is None):\n",
    "        train_preds = clf.predict(dfulltrain)\n",
    "        test_preds = clf.predict(dfulltest)\n",
    "    else:\n",
    "        train_preds *= clf.predict(dfulltrain)\n",
    "        test_preds *= clf.predict(dfulltest)\n",
    "    del dfulltrain\n",
    "    del dfulltest\n",
    "    del clf\n",
    "    gc.collect()\n",
    "\n",
    "train_preds = np.power(train_preds, 1./index)\n",
    "test_preds = np.power(test_preds, 1./index)\n",
    "print('Average Log Loss:', log_loss(train.TARGET.values, train_preds))\n",
    "print('Average ROC:', roc_auc_score(train.TARGET.values, train_preds))\n",
    "submission = pd.DataFrame({\"ID\": train.ID,\n",
    "                           \"TARGET\": train.TARGET,\n",
    "                           \"PREDICTION\": train_preds})\n",
    "\n",
    "submission.to_csv(\"simplexgbtrain.csv\", index=False)\n",
    "submission = pd.DataFrame({\"ID\": test.ID, \"TARGET\": test_preds})\n",
    "submission.to_csv(\"simplexgbtest.csv\", index=False)\n",
    "print('Finish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
